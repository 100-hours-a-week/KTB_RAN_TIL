## **HTTP 캐시**

> **웹 리소스들**을
>사용자의 브라우저나 서버에
>**임시로 저장**해두는 기술


**→ 리소스를 빠르게 공급받아오기 위해서**

**예시**

- 교재 사이트 접근 → 웹서버는 **모든** 사용자에게 **매번** 리소스 요청에 응답해야한다.

- 만약, 캐시 존재 ) 이전에 응답받은 리소스를 재사용 → 연산이 줄어들어 → **트래픽이 분산**되어 요청처리가 빠르다.

**→ 네트워크 전송량(트래픽)을 줄이기 위해**, 웹 브라우저와 웹서버 사이에 임시저장소를 만들어서 리소스결과를 재사용함.

![image.png](attachment:22584f6c-3131-44f4-972d-077912b29b46:image.png)

- **Proxy Cache : 개인 브라우저 내에 구현** / 사용자가 방문한 웹사이트의 리소스를 저장하고, 재 방문시 빠르게 제공합니다.
- **Shared Cache** : 여러 사용자가 접근 가능하기 때문에, 공통 리소스 접근

< 왼쪽으로 갈 수록 **개인화된** 캐시
오른쪽으로 갈수록 **공통**으로 사용되는 캐시>

**전반적인 캐시 목적은 같음 : 빈번하게 발생하는 동일한 리소스 응답 경우를 줄이고 재활용하여 트래픽을 줄이기 위해**

성능, 트래픽 비용, 응답속도 향상 → 사용자경험 향상 , 확장과 유지보수

💡 WebRTC / HLS 란?

  - **WebRTC (Web Real Time Communication)**

  - 브라우저 간 **실시간 양방향으로 통신**이 가능하도록 하는 기술


  - 사용 예) 화상 회의, 실시간 방송, 게임 스트리밍 등 **즉각적인 상호작용**이 필요한 서비스

💡 **HLS(HTTP Live Streaming)**

  - 애플이 만든 **HTTP 기반 스트리밍 프로토콜**

  - 비디오를 작은 MP4 세그먼트로 나누고 M3U8 playlist에 제공

  → 비디오를 다양한 기기에서 지원 가능하도록 변환해주는 기술

  대부분의 모든 기기에서 지원 / CDN을 통한 대규모 확장 가능 
  - 단점 : 지연이 크다.



> **캐시 정책 존재**
>

캐시가 네트워크 전송률을 줄여주고 응답속도가 빨라지지만, 부작용(스파이크 트래픽)이 존재.

부작용을 해결하기 위해 **정책과 알고리즘**이 필요해졌다.

1. **캐시 무효화**

캐시의 **저장된 데이터가 오래돼서 원본과 달라졌을 때,** 언제, 또는 어떻게 캐시를 무효화 할지 결정하는데에 어려움이 생긴다.

→ 캐시가 원본과 같지 않으면, 사용자는 오래된 데이터를 받게 됩니다.

2. 트래픽 폭증 (스파이크 트래픽 )문제

동시 다발적으로 **같은 리소스를 요청**하지만, 캐시가 없을 경우 **원본 리소스에 요청**이 몰리게 됩니다.

이때 이것을 캐시 미스 폭풍 : 쇼핑몰 타임 세일 시작 순간 및 티켓팅 ?

**→ Cache Stampede 캐시 쇄도에 대한 기술블로그**

[캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁](https://toss.tech/article/cache-traffic-tip)

💡 **스파이크 트래픽이란?** 특정 시간에 비정상적으로 요청이 몰리는 현상

- DB에대해서

  내 PC에 DB를 만들었을때 DB는 로컬 디스크 (HDD, SSD)에 저장된다.

  DB의 핵심 특징은 **영속성**이라는 부분이다.

  디스크는 **비휘발성 저장장치** 이기 때문에, DB를 저장할 수 있다.

  → 게임 및 폴더를 생성했을때 모두 디스크에 저장된다.

  **때문에, 디스크에 저장된 데이터는 컴퓨터의 전원이 꺼져도 유지 됩니다.**


- **Redis란?**

  인메모리 방식을 사용하여 데이터를 디스크가 아닌 RAM에 저장하여서 비교적 데이터를 빠르게 조회하고 저장할 수 있도록 한다.

  [[개발] Redis란, Redis의 캐싱 기능에 대해서](https://velog.io/@ssssujini99/%EA%B0%9C%EB%B0%9C-Redis%EB%9E%80-Redis%EC%9D%98-%EC%BA%90%EC%8B%B1-%EA%B8%B0%EB%8A%A5%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C)

    - **Redis를 사용하는 이유**
        - 데이터베이스는 물리 디스크에 직접쓰기 때문에 서버가 다운되어도 데이터는 보존된다.

          → **문제 :** 매번 물리 디스크에 접근하면 사용자가 많아 질수록 부하 증가

        - 문제 해결을 위해 cache server 도입 → cache server로 redis를 사용할 수 있다.
        - cache server는 한번 요청하여 받아온 리소스는 redis에서 캐시로 저장한다.
        - 데이터베이스 부하 감소, 서비스 속도 향상

> **트래픽과 부하 정의**
>

**트래픽 :** 서버에 오는 요청 량 (요청량)

**부하** : 요청을 처리하는 양 (처리량)

- 트래픽이 많아질수록 부하가 증가함.

→ redis를 single thread와 같이 쓴다고라?

---

> **Gateway와 port의 정의**
>

**Gateway** : 네트워크 간의 연결 역할을 하는 출입구

→ 아파트 단지에서 외부로 나가려면 정문 (Gateway)를 통해 나가야된다.

**port :** 한 서버 안에 다양한 프로그램을 구분하기 위한 논리적인 번호

→ 한 아파트에는 여러 호수 가 존재한다. 각각의 호수(프로그램을 가리키는 역할)에는 각각의 다른 가족(프로그램)이 살고 있다.

> **캐시 동작 흐름 (예시: 웹 브라우저 캐시)**
>
1. 사용자가 `example.com/logo.png` 요청
2. 브라우저는 **캐시 디렉토리** 확인
    - 있으면(Cache Hit) → 캐시에서 바로 가져옴
    - 없으면(Cache Miss) → 원본 저장소에서 가져옴
3. **Cache Miss 처리**
    - 원본 저장소(DB, 디스크, 원격 서버 등)에서 데이터를 가져옴
    - 가져온 데이터를 캐시에 저장해 둠 (다음 요청을 대비)
4. 서버 응답 시 **Cache-Control 헤더** 정책에 따라 저장
    - `max-age`, `no-cache`, `etag` 등 설정에 따름
    1. 일정 시간 지나거나 교체 정책에 따라 캐시에서 제거됨
    2. 이때 **교체 알고리즘**(Replacement Policy)이 적용됨
    - LRU (Least Recently Used): 가장 오래 사용 안 한 것 제거
    - LFU (Least Frequently Used): 사용 빈도가 낮은 것 제거
    - FIFO (First In First Out): 먼저 들어온 것부터 제거



## SWR 전략

Stale While Revailable

오래된 데이터를 즉시 사용자에게 보여주고 반면 백그라운드에서는 데이터 재검증을 통해 최신 데이터를 요청해와서 UI를 업데이트

vercel에서 React Hooks로  데이터 패칭 기법을 개발함.

- **목적 :** 사용자 경험이 끊김없이 응답성을 유지하면서 데이터의 정확성과 신선도 보장

- **키워드 :** 최신성, 백그라운드, 사용자 경험


> **실제 작동방식**

1. **초기 캐시 로딩 :** 웹 브라우저에 요청하면 **이전에 서버가 받은 캐시**를 불러옵니다.
2. **백그라운드 최신 데이터 요청 :** 페이지가 로드된 후 백그라운드에서 **서버로부터 최신 데이터 요청**
3. **데이터 업데이트 표시 :** 최신 데이터를 제공 받게 되면 즉시 페이지는 자동으로 업데이트합니다.